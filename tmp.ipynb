{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Around-The-World-In-80-Days.txt', 'Harry-Potter-01-and-the-Sorcerors-Stone.txt', 'Harry-Potter-02-and-the-Chamber-of-Secrets.txt', 'Harry-Potter-03-and-The-Prisoner-of-Azkaban.txt', 'Harry-Potter-04-and-the-Goblet-of-Fire.txt', 'Harry-Potter-05-and-the-Order-of-the-Phoenix.txt', 'Harry-Potter-06-and-the-Half-Blood-Prince.txt', 'Harry-Potter-07-and-the-Deathly-Hallows.txt', 'Moby-Dick.txt', 'The-Hobbit.txt', 'Twenty-Thousand-Leagues-Under-The-Sea.txt']\n",
      "Skipping Around-The-World-In-80-Days.txt\n",
      "Skipping Harry-Potter-01-and-the-Sorcerors-Stone.txt\n",
      "Skipping Harry-Potter-02-and-the-Chamber-of-Secrets.txt\n",
      "Skipping Harry-Potter-03-and-The-Prisoner-of-Azkaban.txt\n",
      "Skipping Harry-Potter-04-and-the-Goblet-of-Fire.txt\n",
      "Skipping Harry-Potter-05-and-the-Order-of-the-Phoenix.txt\n",
      "Skipping Harry-Potter-06-and-the-Half-Blood-Prince.txt\n",
      "Skipping Harry-Potter-07-and-the-Deathly-Hallows.txt\n",
      "Skipping Moby-Dick.txt\n",
      "Skipping The-Hobbit.txt\n",
      "Skipping Twenty-Thousand-Leagues-Under-The-Sea.txt\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"./books\")\n",
    "files = [file for file in files if file.endswith(\".txt\") and not \"split\" in file]\n",
    "print(files)\n",
    "\n",
    "already_saved_files = os.listdir(\"./books/saves\")\n",
    "already_saved_files = [file for file in already_saved_files if file.endswith(\".txt\")]\n",
    "\n",
    "for file in files:\n",
    "    if file in already_saved_files:\n",
    "        print(f\"Skipping {file}\")\n",
    "        continue\n",
    "    \n",
    "    with open(f\"./books/{file}\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    lines_out = []\n",
    "    sub_txt = \"\"\n",
    "    chapter_texts = set()\n",
    "    for line in lines:\n",
    "        if line.strip().lower().startswith(\"chapter\"):\n",
    "            # handle chapter\n",
    "            if sub_txt:\n",
    "                lines_out.extend(sent_tokenize(sub_txt))\n",
    "                sub_txt = \"\"\n",
    "            \n",
    "            chapter_text = line.strip()\n",
    "            # seek forward until we get an empty line\n",
    "            next_line = lines[lines.index(line) + 1]\n",
    "            print(chapter_text, \"|\", next_line)\n",
    "            while not next_line.strip() == \"\":\n",
    "                chapter_text += \" \" + next_line.strip()\n",
    "                next_line = lines[lines.index(next_line) + 1]\n",
    "            chapter_text += \"\\n\"\n",
    "            chapter_texts.add(chapter_text)\n",
    "            print(chapter_text)\n",
    "            lines_out.append(chapter_text)\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            if any(line.strip() in chapter_text for chapter_text in chapter_texts):\n",
    "                continue\n",
    "            sub_txt += line.strip() + \" \"\n",
    "\n",
    "    if sub_txt:\n",
    "        lines_out.extend(sent_tokenize(sub_txt))\n",
    "    \n",
    "\n",
    "    # Split lines longer than 150 characters\n",
    "    lines_out_out = []\n",
    "    for idx, line in enumerate(lines_out):\n",
    "        if len(line) > 150:\n",
    "            # Define potential split points in order of preference\n",
    "            split_markers = ['. ', '; ', ', ', ' and ', ' but ', ' or ', ' ', '\\n']\n",
    "            text_parts = []\n",
    "            current_text = line\n",
    "            \n",
    "            while len(current_text) > 150:\n",
    "                split_found = False\n",
    "                # Try each marker in order until we find one within the 150 char limit\n",
    "                for marker in split_markers:\n",
    "                    # Find the last occurrence of the marker within first 150 chars\n",
    "                    pos = current_text[:150].rfind(marker)\n",
    "                    if pos != -1:\n",
    "                        # Split at the marker\n",
    "                        text_parts.append(current_text[:pos + len(marker)].strip())\n",
    "                        current_text = current_text[pos + len(marker):].strip()\n",
    "                        split_found = True\n",
    "                        break\n",
    "                \n",
    "                # If no marker found, force split at 150\n",
    "                if not split_found:\n",
    "                    text_parts.append(current_text[:150])\n",
    "                    current_text = current_text[150:].strip()\n",
    "            \n",
    "            if current_text:  # Add remaining text\n",
    "                text_parts.append(current_text)\n",
    "            \n",
    "            # Replace original line with split lines\n",
    "            lines_out_out.extend(text_parts)\n",
    "        else:\n",
    "            lines_out_out.append(line)\n",
    "\n",
    "    # save original text\n",
    "    with open(f\"./books/saves/{file}\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "    \n",
    "    # save split text\n",
    "    with open(f\"./books/{file}\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(lines_out_out))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
